{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06e34966-addd-4e4e-b93f-35158155aca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e8438f-54dd-42e6-ac2f-d2ef0b6f7aac",
   "metadata": {},
   "source": [
    "## Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a63018e-1c77-40f3-bc43-677bc763ca40",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "538f6ab0-dd01-4229-a8c9-5a4392774b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8005 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train = test_datagen.flow_from_directory(r'Animals_dataset\\training_set\\training_set',\n",
    "    target_size=(64,64),\n",
    "    class_mode='binary',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55cc1e00-5ede-4a65-abed-51b9d24736a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cats': 0, 'dogs': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39822de3-f261-4525-ac3b-76198d1f86af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2023 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test = test_datagen.flow_from_directory(r'Animals_dataset\\test_set\\test_set',\n",
    "    target_size=(64,64),\n",
    "    class_mode='binary',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fcce053-bd23-46cf-8b09-e5c1c61ef81d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cats': 0, 'dogs': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932e2f68-df92-48ce-b075-b4b622d2bea2",
   "metadata": {},
   "source": [
    "## Modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71a74b3a-e346-42b9-8f4d-9df07784c230",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662b59e2-bf01-46e0-bf1a-e11e31baa184",
   "metadata": {},
   "source": [
    "### Step 1 Convolution\n",
    "*  For a color image, we set the input shape as (64, 64, 3), where \"3\" represents the RGB channels. \n",
    "For a grayscale (black & white) image, the input shape would be (64, 64, 1), since there is only a single channel. \n",
    "\n",
    "The number of filters determines how many feature maps are generated in the convolutional layer. \n",
    "For example, setting filters=32 means the layer will learn 32 different feature detectors. \n",
    "\n",
    "Increasing the number of filters generally improves the model’s ability to capture complex patterns, \n",
    "which can lead to higher accuracy. However, it also increases computational cost and training time. \n",
    "Therefore, there is a trade-off: more filters → better accuracy (up to a limit), but higher processing requirements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfe064fe-7311-403e-9834-64429145701f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D\n",
    "classifier.add(Conv2D(input_shape =[64,64,3], \n",
    "                      filters = 32,\n",
    "                      kernel_size = 3,   # 3 × 3 matrix filter\n",
    "                      activation = 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d77b5af-1a3f-4e38-9632-a4052e3a8971",
   "metadata": {},
   "source": [
    "### step 2 - Max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7617326b-7e4f-427c-8e1b-d764977717ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(MaxPooling2D(pool_size = 2,strides = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2fd5a9-1a95-4685-bfd6-43e0dd6340f5",
   "metadata": {},
   "source": [
    "### Step3 - flattening\n",
    "* Inputs Layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b8495ab-ba85-42d2-aec1-7d445a3299cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937a0d5f-2d8c-4dd3-8c59-e588112f4ece",
   "metadata": {},
   "source": [
    "### Step 4 - Full Connection\n",
    "* Hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a82f1b4d-0a5e-433f-8460-e187d3c7eda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden layer \n",
    "classifier.add(Dense(units = 128,activation = 'relu'))\n",
    "# hidden layer \n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b8eb60-0835-4e8d-9634-30dbaa1013cb",
   "metadata": {},
   "source": [
    "##### Training the CNN model with train data and test the model with the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0e5dddd-b4fe-4c71-93c2-e9ea518304b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'adam',\n",
    "                           loss = 'binary_crossentropy',\n",
    "                           metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c289e643-9194-4015-b17e-af063be11eca",
   "metadata": {},
   "source": [
    "## how to improve the accuracy \n",
    "* increase the imput data \n",
    "* add one convolution layer + max pooling or add hidden layer or increase the no of pixels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7d5b6e4-1501-4ac9-98fc-f5c92897ea0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 144ms/step - accuracy: 0.6169 - loss: 0.6832 - val_accuracy: 0.6653 - val_loss: 0.6032\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1a3325ad1f0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(x = train,validation_data = test,epochs= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a126823e-808a-4778-b3df-70b7f617789b",
   "metadata": {},
   "source": [
    "* because of system configration i take 1 epoch "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
